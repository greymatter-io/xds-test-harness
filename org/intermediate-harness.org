#+TITLE: Intermediate Harness
#+PROPERTY: header-args :results output

* Goal
Setup a harness that models the initial diagram in the SoW, with a test case
being read by a test runner, the runner setting up the necessary state on the
target via a test adapter, and running through a real-life test scenario: in
this case, sending a discovery request, and receiving the appropriate discovery
response.
* Long-Term Goals
This is a Proof-of-Concept, but I still want to set up some patterns that will
be important for the eventual test framework.
1. *Test Cases are separate from their implementation*
   The cases should be written in a spec that can be implemented in a variety of
   languages. Perhaps some of the tests may be best implemented in Golang, and
   some may be best implemented in Python. No matter which, the style in which
   the test is written should not change based on the test runners'
   implementation.
2. *Language-Agnostic Adapter*
   The adapter should, similarly, be language-agnostic. The point of the adapter
   is to be able to communicate with a target and set up its necessary state. As
   each target will be implemented differently, and likely in different
   languages, we do not want to have to write a new adapter per target. Instead,
   it should be an api that can be implemented on the target and runner, so
   there is a known contract to set up and retrieve state.
3. *Adapter is separate from the runner*
   As the adapter is an API, and an implementation of that api, we could
   implement the testing half directly into the test runner. This would reduce
   the surface area of the framework. However, as we have not explored all the
   test scenarios yet, it could be possible that someo f these scenarios need
   specialized runners to implement. In this case, we'd want each runner to
   interact with the same adapter, so we are not having to write multiple
   versions of the same API. Because of this, we will have the adapter be a
   separate server that the runner connects to, to make the framework more
   modular.

   We may find later on that this was an incorrect assumption, and all the tests
   can be implemented in similar ways in one runner. In that case, it would make
   sense for the testing adapter to be a part of the runner itself. This is
   somethiong we'll want to return to and discuss more.






* Current Layout
The initial Harness is made of the following components:
- Test Cases (spec) ::
  These are a set of files written in [[https://cucumber.io/docs/gherkin/][gherkin]]. The syntax follows a
  specification, but is implementation-agnostic. In this harness, they are
  stored in [[file:~/Projects/xDS-conformance/test-harness/tests/features/][tests/features]]
- Tests and Test Runner ::
  These are the implementations of the test cases.
  At this moment, we have a single implemented test, at [[file:~/Projects/xDS-conformance/test-harness/tests/acknack_test.go][tests/acknack_test.go]]
  Our runner is simple: the [[https://github.com/cucumber/godog][godog binary]].

  When we run godog in our [[file:~/Projects/xDS-conformance/test-harness/tests/][tests]] directory, it compiles all our feature files and
  any test files, and matches the test implementation to each line in the test
  case.
- Adapter api (spec) ::
  This is a proto file held at [[file:~/Projects/xDS-conformance/test-harness/api/adapter/adapter.proto][api/adapter/adapter.proto]]. It specifies the
  services between both the runner and the adapter, and the adapter and the
  target. Each target can then check out this proto, implement its half in their
  target-specific way, then let the runner know how to connect to the adapter.
- Test Adapter ::
  This is the implementation of the testing half of the adapter. It is located
  at [[file:~/Projects/xDS-conformance/test-harness/adapter/main.go][adapter/main.go]] and is meant to be run separate from the test runner, based
  on the long-term goals outlined above.
*  Benefit of Gherkin for test-writing
  An exciting part of this style is that we can write the tests in a consistent,
  generic pattern that is then implemented by a set of resuable test functions.

  For example, you could have any number of tests written in this pattern.

  #+begin_example feature
  Given A server with starting state matching snapshot yaml:
  ```yaml
  ## starting state
  ```
  When a Client sends discovery request matching yaml:
  ```yaml
  ## discoveryRequest
  ```
  Then it receives a discovery response matching yaml:
 ```
 ## discoveryResponse
 ```
  #+end_example

  And each would be implemented using the same set of functions. The difference
  between tests, then, is in the beginning state, and the requests and responses
  given out.

  This allows for test writers to only have to write in human-readable gherkin,
  knowing that as long as they follow an outlined pattern, the implementation
  will be handled automatically. It is also a style that matches a lot of the
  existing envoy and xDS docs.




 


* Dev Diary
** Initial Test Case
:PROPERTIES:
:header-args: :tangle (ii/workdir+ "tests/features/acknack.feature")
:END:

A simple test I can run is, basically "if there's a target with a cluster resource named foo, and i send a discovery request for clusters, it should send me a discovery response with foo."

In gherkin, this is written as:

#+NAME: acknack test
#+begin_src feature
Feature: Conformance ACK/NACK
  Discovery Requests and Responses should follow the behaviour outlined in the
  API docs.

  Background:
    Given "adapter" is reachable via grpc
    And "target" is reachable via grpc
    And "target_adapter" is reachable via grpc

  Scenario:
    Given a Target setup with snapshot matching yaml:
     ```
     ---
     Node:
       name: test-id
     Resources:
     - Version: '1'
       Items: {}
     - Version: '1'
       Items:
         foo:
           Resource:
             name: foo
             connect_timeout:
               seconds: 5
     - Version: '1'
       Items: {}
     - Version: '1'
       Items: {}
     - Version: '1'
       Items: {}
     - Version: '1'
       Items: {}
     - Version: '1'
       Items: {}
     ```
     When I send a discovery request matching yaml:
     ```
     version_info:
     node: { id: test-id }
     resource_names:
     type_url: type.googleapis.com/envoy.config.cluster.v3.Cluster
     response_nonce:
     ```
     Then I get a discovery response matching json:
     ```
     {
       "versionInfo":"1",
       "resources":[
         {"typeUrl":"type.googleapis.com/envoy.config.cluster.v3.Cluster",
          "value":"CgNmb28iAggF"}
        ],
        "typeUrl":"type.googleapis.com/envoy.config.cluster.v3.Cluster"
     }
     ```
#+end_src

The background segment sets up the required layout for our harness. We will
implement a --config flag that sets the ports for the adapter, target, and
target adapter. The port for the target and its adapter could be the same, if
that is hwo they implemented in it. In our test target implementation, we have
it reachable through a separate port.

I am intending for the state to match the format of a snapshot cache as closely
as possible, while remaining readable yaml. Similarly, the request and response
should follow the formats given in the xDS docs.

* Generate Test Outline using godog

In our tests folder, i can run godog and get a suggested outline for our tests.

#+NAME: generate test outline
#+begin_src shell :dir (ii/workdir+ "tests")
godog
#+end_src

#+RESULTS: generate test outline
#+begin_example
Feature: Conformance ACK/NACK
  Discovery Requests and Responses should follow the behaviour outlined in the
  API docs.

  Background:
    Given "adapter" is reachable via grpc
    And "target" is reachable via grpc
    And "target_adapter" is reachable via grpc

  Scenario:                                          # features/acknack.feature:10
    Given a Target setup with snapshot matching yaml:
      ```
      ---
      Node:
        name: test-id
      Resources:
      - Version: '1'
        Items: {}
      - Version: '1'
        Items:
          foo:
            Resource:
              name: foo
              connect_timeout:
                seconds: 5
      - Version: '1'
        Items: {}
      - Version: '1'
        Items: {}
      - Version: '1'
        Items: {}
      - Version: '1'
        Items: {}
      - Version: '1'
        Items: {}
      ```
    When I send a discovery request matching yaml:
      ```
      version_info:
      node: { id: test-id }
      resource_names:
      type_url: type.googleapis.com/envoy.config.cluster.v3.Cluster
      response_nonce:
      ```
    Then I get a discovery response matching json:
      ```
      {
        "versionInfo":"1",
        "resources":[
          {"typeUrl":"type.googleapis.com/envoy.config.cluster.v3.Cluster",
           "value":"CgNmb28iAggF"}
         ],
         "typeUrl":"type.googleapis.com/envoy.config.cluster.v3.Cluster"
      }
      ```

1 scenarios (1 undefined)
6 steps (6 undefined)
1.016742ms

You can implement step definitions for undefined steps with these snippets:

func aTargetSetupWithSnapshotMatchingYaml(arg1 *messages.PickleStepArgument_PickleDocString) error {
	return godog.ErrPending
}

func iGetADiscoveryResponseMatchingJson(arg1 *messages.PickleStepArgument_PickleDocString) error {
	return godog.ErrPending
}

func iSendADiscoveryRequestMatchingYaml(arg1 *messages.PickleStepArgument_PickleDocString) error {
	return godog.ErrPending
}

func isReachableViaGrpc(arg1 string) error {
	return godog.ErrPending
}

func InitializeScenario(ctx *godog.ScenarioContext) {
	ctx.Step(`^a Target setup with snapshot matching yaml:$`, aTargetSetupWithSnapshotMatchingYaml)
	ctx.Step(`^I get a discovery response matching json:$`, iGetADiscoveryResponseMatchingJson)
	ctx.Step(`^I send a discovery request matching yaml:$`, iSendADiscoveryRequestMatchingYaml)
	ctx.Step(`^"([^"]*)" is reachable via grpc$`, isReachableViaGrpc)
}

#+end_example


Notice that there are multiple lines in our background and example, but only four steps.  Since we are writing them in a consistent way, we can develop generic, reusable functions for them, reducing complexity.

* Implementing the first test
